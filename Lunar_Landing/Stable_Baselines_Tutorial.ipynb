{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.15.0 tensorflow-gpu==1.15.0 stable_baselines gym box2d-py --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym \n",
    "from stable_baselines import ACER\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'LunarLander-v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test Random Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-117.42800566285462\n",
      "Episode:2 Score:-221.5901611372018\n",
      "Episode:3 Score:-103.02637740513153\n",
      "Episode:4 Score:-114.56307978687623\n",
      "Episode:5 Score:-401.2705869759806\n",
      "Episode:6 Score:-122.73167364496194\n",
      "Episode:7 Score:-198.68632709242547\n",
      "Episode:8 Score:-127.68905207801089\n",
      "Episode:9 Score:-258.4556793059761\n",
      "Episode:10 Score:-121.32792106934696\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = ACER('MlpPolicy', env, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 4.45     |\n",
      "| avg_norm_g          | 18.8     |\n",
      "| avg_norm_grads_f    | 16.3     |\n",
      "| avg_norm_k          | 2        |\n",
      "| avg_norm_k_dot_g    | 18.8     |\n",
      "| entropy             | 29.1     |\n",
      "| explained_variance  | 2.52e-05 |\n",
      "| fps                 | 0        |\n",
      "| loss                | 0.978    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -6.48    |\n",
      "| loss_policy         | -6.48    |\n",
      "| loss_q              | 15.5     |\n",
      "| mean_episode_length | 0        |\n",
      "| mean_episode_reward | 0        |\n",
      "| norm_grads          | 5.87     |\n",
      "| norm_grads_policy   | 4.4      |\n",
      "| norm_grads_q        | 3.89     |\n",
      "| total_timesteps     | 20       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 68.3     |\n",
      "| avg_norm_g          | 275      |\n",
      "| avg_norm_grads_f    | 238      |\n",
      "| avg_norm_k          | 2.01     |\n",
      "| avg_norm_k_dot_g    | 277      |\n",
      "| entropy             | 29       |\n",
      "| explained_variance  | -0.0195  |\n",
      "| fps                 | 403      |\n",
      "| loss                | 1.14e+03 |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -94.6    |\n",
      "| loss_policy         | -94.6    |\n",
      "| loss_q              | 2.46e+03 |\n",
      "| mean_episode_length | 91.8     |\n",
      "| mean_episode_reward | -202     |\n",
      "| norm_grads          | 85.5     |\n",
      "| norm_grads_policy   | 25.2     |\n",
      "| norm_grads_q        | 81.7     |\n",
      "| total_timesteps     | 2020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 41       |\n",
      "| avg_norm_grads_f    | 41       |\n",
      "| avg_norm_k          | 2.38     |\n",
      "| avg_norm_k_dot_g    | 45.3     |\n",
      "| entropy             | 24.1     |\n",
      "| explained_variance  | -0.142   |\n",
      "| fps                 | 373      |\n",
      "| loss                | 45.9     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 12.5     |\n",
      "| loss_policy         | 12.5     |\n",
      "| loss_q              | 67.3     |\n",
      "| mean_episode_length | 105      |\n",
      "| mean_episode_reward | -193     |\n",
      "| norm_grads          | 28.1     |\n",
      "| norm_grads_policy   | 8.71     |\n",
      "| norm_grads_q        | 26.7     |\n",
      "| total_timesteps     | 4020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.7      |\n",
      "| avg_norm_g          | 9.27     |\n",
      "| avg_norm_grads_f    | 8.16     |\n",
      "| avg_norm_k          | 2.29     |\n",
      "| avg_norm_k_dot_g    | 10.3     |\n",
      "| entropy             | 21.2     |\n",
      "| explained_variance  | -0.00106 |\n",
      "| fps                 | 358      |\n",
      "| loss                | 0.133    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.74    |\n",
      "| loss_policy         | -1.74    |\n",
      "| loss_q              | 4.16     |\n",
      "| mean_episode_length | 134      |\n",
      "| mean_episode_reward | -172     |\n",
      "| norm_grads          | 6.74     |\n",
      "| norm_grads_policy   | 1.76     |\n",
      "| norm_grads_q        | 6.51     |\n",
      "| total_timesteps     | 6020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.193    |\n",
      "| avg_norm_g          | 10.8     |\n",
      "| avg_norm_grads_f    | 10.6     |\n",
      "| avg_norm_k          | 2.42     |\n",
      "| avg_norm_k_dot_g    | 11       |\n",
      "| entropy             | 23.8     |\n",
      "| explained_variance  | 0.204    |\n",
      "| fps                 | 343      |\n",
      "| loss                | 9.43     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 3.07     |\n",
      "| loss_policy         | 3.07     |\n",
      "| loss_q              | 13.2     |\n",
      "| mean_episode_length | 167      |\n",
      "| mean_episode_reward | -147     |\n",
      "| norm_grads          | 12.7     |\n",
      "| norm_grads_policy   | 5.32     |\n",
      "| norm_grads_q        | 11.6     |\n",
      "| total_timesteps     | 8020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 10.5     |\n",
      "| avg_norm_g          | 50.6     |\n",
      "| avg_norm_grads_f    | 44.8     |\n",
      "| avg_norm_k          | 2.4      |\n",
      "| avg_norm_k_dot_g    | 48.7     |\n",
      "| entropy             | 12.6     |\n",
      "| explained_variance  | 0.0824   |\n",
      "| fps                 | 331      |\n",
      "| loss                | 571      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -8.77    |\n",
      "| loss_policy         | -8.77    |\n",
      "| loss_q              | 1.16e+03 |\n",
      "| mean_episode_length | 215      |\n",
      "| mean_episode_reward | -132     |\n",
      "| norm_grads          | 215      |\n",
      "| norm_grads_policy   | 23       |\n",
      "| norm_grads_q        | 213      |\n",
      "| total_timesteps     | 10020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 18.3     |\n",
      "| avg_norm_g          | 80.3     |\n",
      "| avg_norm_grads_f    | 70.8     |\n",
      "| avg_norm_k          | 2.14     |\n",
      "| avg_norm_k_dot_g    | 73.1     |\n",
      "| entropy             | 9.83     |\n",
      "| explained_variance  | -0.0412  |\n",
      "| fps                 | 331      |\n",
      "| loss                | 703      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -25.5    |\n",
      "| loss_policy         | -25.5    |\n",
      "| loss_q              | 1.46e+03 |\n",
      "| mean_episode_length | 243      |\n",
      "| mean_episode_reward | -124     |\n",
      "| norm_grads          | 208      |\n",
      "| norm_grads_policy   | 74.4     |\n",
      "| norm_grads_q        | 194      |\n",
      "| total_timesteps     | 12020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 68.7     |\n",
      "| avg_norm_g          | 263      |\n",
      "| avg_norm_grads_f    | 224      |\n",
      "| avg_norm_k          | 2.02     |\n",
      "| avg_norm_k_dot_g    | 275      |\n",
      "| entropy             | 11.4     |\n",
      "| explained_variance  | -0.257   |\n",
      "| fps                 | 328      |\n",
      "| loss                | 108      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -8.63    |\n",
      "| loss_policy         | -8.63    |\n",
      "| loss_q              | 233      |\n",
      "| mean_episode_length | 262      |\n",
      "| mean_episode_reward | -106     |\n",
      "| norm_grads          | 164      |\n",
      "| norm_grads_policy   | 75.7     |\n",
      "| norm_grads_q        | 145      |\n",
      "| total_timesteps     | 14020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.48     |\n",
      "| avg_norm_g          | 11.8     |\n",
      "| avg_norm_grads_f    | 9.82     |\n",
      "| avg_norm_k          | 3.42     |\n",
      "| avg_norm_k_dot_g    | 20.8     |\n",
      "| entropy             | 9.16     |\n",
      "| explained_variance  | 0.198    |\n",
      "| fps                 | 328      |\n",
      "| loss                | 7.35     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.3     |\n",
      "| loss_policy         | -1.3     |\n",
      "| loss_q              | 17.5     |\n",
      "| mean_episode_length | 281      |\n",
      "| mean_episode_reward | -106     |\n",
      "| norm_grads          | 6.63     |\n",
      "| norm_grads_policy   | 1.7      |\n",
      "| norm_grads_q        | 6.41     |\n",
      "| total_timesteps     | 16020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 7.35     |\n",
      "| avg_norm_g          | 29.2     |\n",
      "| avg_norm_grads_f    | 25       |\n",
      "| avg_norm_k          | 1.89     |\n",
      "| avg_norm_k_dot_g    | 29.2     |\n",
      "| entropy             | 11.8     |\n",
      "| explained_variance  | 0.541    |\n",
      "| fps                 | 323      |\n",
      "| loss                | 79.6     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -8.37    |\n",
      "| loss_policy         | -8.37    |\n",
      "| loss_q              | 176      |\n",
      "| mean_episode_length | 310      |\n",
      "| mean_episode_reward | -103     |\n",
      "| norm_grads          | 168      |\n",
      "| norm_grads_policy   | 18       |\n",
      "| norm_grads_q        | 167      |\n",
      "| total_timesteps     | 18020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.611    |\n",
      "| avg_norm_g          | 6.36     |\n",
      "| avg_norm_grads_f    | 5.94     |\n",
      "| avg_norm_k          | 2.22     |\n",
      "| avg_norm_k_dot_g    | 6.8      |\n",
      "| entropy             | 21.1     |\n",
      "| explained_variance  | 0.732    |\n",
      "| fps                 | 320      |\n",
      "| loss                | 0.0981   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.386   |\n",
      "| loss_policy         | -0.386   |\n",
      "| loss_q              | 1.39     |\n",
      "| mean_episode_length | 309      |\n",
      "| mean_episode_reward | -107     |\n",
      "| norm_grads          | 7.88     |\n",
      "| norm_grads_policy   | 2.63     |\n",
      "| norm_grads_q        | 7.43     |\n",
      "| total_timesteps     | 20020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 269      |\n",
      "| avg_norm_grads_f    | 269      |\n",
      "| avg_norm_k          | 1.63     |\n",
      "| avg_norm_k_dot_g    | 194      |\n",
      "| entropy             | 10.5     |\n",
      "| explained_variance  | -0.163   |\n",
      "| fps                 | 317      |\n",
      "| loss                | 2.66e+03 |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 64.9     |\n",
      "| loss_policy         | 64.9     |\n",
      "| loss_q              | 5.18e+03 |\n",
      "| mean_episode_length | 315      |\n",
      "| mean_episode_reward | -99.8    |\n",
      "| norm_grads          | 1.09e+03 |\n",
      "| norm_grads_policy   | 131      |\n",
      "| norm_grads_q        | 1.08e+03 |\n",
      "| total_timesteps     | 22020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| avg_norm_adj        | 0.933    |\n",
      "| avg_norm_g          | 8.26     |\n",
      "| avg_norm_grads_f    | 7.55     |\n",
      "| avg_norm_k          | 1.95     |\n",
      "| avg_norm_k_dot_g    | 7.67     |\n",
      "| entropy             | 11.4     |\n",
      "| explained_variance  | 0.748    |\n",
      "| fps                 | 317      |\n",
      "| loss                | 2.74     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.485   |\n",
      "| loss_policy         | -0.485   |\n",
      "| loss_q              | 6.67     |\n",
      "| mean_episode_length | 314      |\n",
      "| mean_episode_reward | -107     |\n",
      "| norm_grads          | 21.5     |\n",
      "| norm_grads_policy   | 7.67     |\n",
      "| norm_grads_q        | 20.1     |\n",
      "| total_timesteps     | 24020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.94     |\n",
      "| avg_norm_g          | 17       |\n",
      "| avg_norm_grads_f    | 15.7     |\n",
      "| avg_norm_k          | 2.3      |\n",
      "| avg_norm_k_dot_g    | 15.7     |\n",
      "| entropy             | 12.5     |\n",
      "| explained_variance  | 0.595    |\n",
      "| fps                 | 316      |\n",
      "| loss                | 23.6     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.97    |\n",
      "| loss_policy         | -0.97    |\n",
      "| loss_q              | 49.5     |\n",
      "| mean_episode_length | 342      |\n",
      "| mean_episode_reward | -94      |\n",
      "| norm_grads          | 102      |\n",
      "| norm_grads_policy   | 4.62     |\n",
      "| norm_grads_q        | 102      |\n",
      "| total_timesteps     | 26020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 3.46     |\n",
      "| avg_norm_g          | 21.5     |\n",
      "| avg_norm_grads_f    | 18.3     |\n",
      "| avg_norm_k          | 2.8      |\n",
      "| avg_norm_k_dot_g    | 29.5     |\n",
      "| entropy             | 10.3     |\n",
      "| explained_variance  | 0.165    |\n",
      "| fps                 | 317      |\n",
      "| loss                | 45.3     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -4.25    |\n",
      "| loss_policy         | -4.25    |\n",
      "| loss_q              | 99.4     |\n",
      "| mean_episode_length | 344      |\n",
      "| mean_episode_reward | -94.1    |\n",
      "| norm_grads          | 57.9     |\n",
      "| norm_grads_policy   | 1.63     |\n",
      "| norm_grads_q        | 57.9     |\n",
      "| total_timesteps     | 28020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 5.67     |\n",
      "| avg_norm_g          | 24.3     |\n",
      "| avg_norm_grads_f    | 21.1     |\n",
      "| avg_norm_k          | 1.98     |\n",
      "| avg_norm_k_dot_g    | 23.9     |\n",
      "| entropy             | 13.1     |\n",
      "| explained_variance  | -0.277   |\n",
      "| fps                 | 316      |\n",
      "| loss                | 38.7     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -5.84    |\n",
      "| loss_policy         | -5.84    |\n",
      "| loss_q              | 89.4     |\n",
      "| mean_episode_length | 356      |\n",
      "| mean_episode_reward | -77.7    |\n",
      "| norm_grads          | 257      |\n",
      "| norm_grads_policy   | 18.4     |\n",
      "| norm_grads_q        | 257      |\n",
      "| total_timesteps     | 30020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0624   |\n",
      "| avg_norm_g          | 2.73     |\n",
      "| avg_norm_grads_f    | 2.7      |\n",
      "| avg_norm_k          | 5.13     |\n",
      "| avg_norm_k_dot_g    | 2.43     |\n",
      "| entropy             | 10       |\n",
      "| explained_variance  | -0.0101  |\n",
      "| fps                 | 313      |\n",
      "| loss                | -0.297   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.549   |\n",
      "| loss_policy         | -0.549   |\n",
      "| loss_q              | 0.703    |\n",
      "| mean_episode_length | 373      |\n",
      "| mean_episode_reward | -71.8    |\n",
      "| norm_grads          | 3.6      |\n",
      "| norm_grads_policy   | 2.74     |\n",
      "| norm_grads_q        | 2.34     |\n",
      "| total_timesteps     | 32020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 10.3     |\n",
      "| avg_norm_grads_f    | 10.3     |\n",
      "| avg_norm_k          | 1.91     |\n",
      "| avg_norm_k_dot_g    | 10.1     |\n",
      "| entropy             | 11.8     |\n",
      "| explained_variance  | 0.828    |\n",
      "| fps                 | 312      |\n",
      "| loss                | 10.5     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 3.01     |\n",
      "| loss_policy         | 3.01     |\n",
      "| loss_q              | 15.2     |\n",
      "| mean_episode_length | 365      |\n",
      "| mean_episode_reward | -35.9    |\n",
      "| norm_grads          | 62.2     |\n",
      "| norm_grads_policy   | 11.6     |\n",
      "| norm_grads_q        | 61.1     |\n",
      "| total_timesteps     | 34020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.143    |\n",
      "| avg_norm_g          | 10.5     |\n",
      "| avg_norm_grads_f    | 10.4     |\n",
      "| avg_norm_k          | 3.14     |\n",
      "| avg_norm_k_dot_g    | 16.5     |\n",
      "| entropy             | 15.7     |\n",
      "| explained_variance  | 0.615    |\n",
      "| fps                 | 310      |\n",
      "| loss                | 3.12     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 1.21     |\n",
      "| loss_policy         | 1.21     |\n",
      "| loss_q              | 4.14     |\n",
      "| mean_episode_length | 369      |\n",
      "| mean_episode_reward | -7.94    |\n",
      "| norm_grads          | 45.1     |\n",
      "| norm_grads_policy   | 5.58     |\n",
      "| norm_grads_q        | 44.8     |\n",
      "| total_timesteps     | 36020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.282    |\n",
      "| avg_norm_g          | 3.41e+04 |\n",
      "| avg_norm_grads_f    | 3.41e+04 |\n",
      "| avg_norm_k          | 2.04     |\n",
      "| avg_norm_k_dot_g    | 3.88e+04 |\n",
      "| entropy             | 6.83     |\n",
      "| explained_variance  | 0.523    |\n",
      "| fps                 | 308      |\n",
      "| loss                | 173      |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 20.4     |\n",
      "| loss_policy         | 20.4     |\n",
      "| loss_q              | 306      |\n",
      "| mean_episode_length | 394      |\n",
      "| mean_episode_reward | -7.62    |\n",
      "| norm_grads          | 314      |\n",
      "| norm_grads_policy   | 77.1     |\n",
      "| norm_grads_q        | 304      |\n",
      "| total_timesteps     | 38020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 1.47     |\n",
      "| avg_norm_g          | 7.42     |\n",
      "| avg_norm_grads_f    | 6.53     |\n",
      "| avg_norm_k          | 2.08     |\n",
      "| avg_norm_k_dot_g    | 7.49     |\n",
      "| entropy             | 12.1     |\n",
      "| explained_variance  | 0.807    |\n",
      "| fps                 | 308      |\n",
      "| loss                | 1.95     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -2.18    |\n",
      "| loss_policy         | -2.18    |\n",
      "| loss_q              | 8.5      |\n",
      "| mean_episode_length | 403      |\n",
      "| mean_episode_reward | 35.7     |\n",
      "| norm_grads          | 48.5     |\n",
      "| norm_grads_policy   | 14.3     |\n",
      "| norm_grads_q        | 46.3     |\n",
      "| total_timesteps     | 40020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 6.01     |\n",
      "| avg_norm_g          | 18.8     |\n",
      "| avg_norm_grads_f    | 12.5     |\n",
      "| avg_norm_k          | 2.2      |\n",
      "| avg_norm_k_dot_g    | 28.8     |\n",
      "| entropy             | 7.76     |\n",
      "| explained_variance  | 0.618    |\n",
      "| fps                 | 305      |\n",
      "| loss                | 31.9     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -2.42    |\n",
      "| loss_policy         | -2.42    |\n",
      "| loss_q              | 68.8     |\n",
      "| mean_episode_length | 407      |\n",
      "| mean_episode_reward | 55.3     |\n",
      "| norm_grads          | 63.2     |\n",
      "| norm_grads_policy   | 20.5     |\n",
      "| norm_grads_q        | 59.8     |\n",
      "| total_timesteps     | 42020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 40.1     |\n",
      "| avg_norm_grads_f    | 40.1     |\n",
      "| avg_norm_k          | 1.55     |\n",
      "| avg_norm_k_dot_g    | 39.2     |\n",
      "| entropy             | 8.51     |\n",
      "| explained_variance  | 0.733    |\n",
      "| fps                 | 305      |\n",
      "| loss                | 62.5     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 9.2      |\n",
      "| loss_policy         | 9.2      |\n",
      "| loss_q              | 107      |\n",
      "| mean_episode_length | 431      |\n",
      "| mean_episode_reward | 86.7     |\n",
      "| norm_grads          | 167      |\n",
      "| norm_grads_policy   | 18.6     |\n",
      "| norm_grads_q        | 166      |\n",
      "| total_timesteps     | 44020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 5.41     |\n",
      "| avg_norm_grads_f    | 5.41     |\n",
      "| avg_norm_k          | 1.72     |\n",
      "| avg_norm_k_dot_g    | 4.37     |\n",
      "| entropy             | 10.5     |\n",
      "| explained_variance  | 0.831    |\n",
      "| fps                 | 305      |\n",
      "| loss                | 1.67     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.989    |\n",
      "| loss_policy         | 0.989    |\n",
      "| loss_q              | 1.58     |\n",
      "| mean_episode_length | 450      |\n",
      "| mean_episode_reward | 122      |\n",
      "| norm_grads          | 22.9     |\n",
      "| norm_grads_policy   | 4.64     |\n",
      "| norm_grads_q        | 22.4     |\n",
      "| total_timesteps     | 46020    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-169c5a1cf084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\acer\\acer_simple.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    576\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_rollout_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[0menc_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_locals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_rollout_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\runners.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, callback)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\acer\\acer_simple.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[0mmb_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb_mus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb_dones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m             \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m             \u001b[0mmus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproba_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mmb_obs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\policies.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, obs, state, mask, deterministic)\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             action, value, neglogp = self.sess.run([self.action, self.value_flat, self.neglogp],\n\u001b[1;32m--> 576\u001b[1;33m                                                    {self.obs_ph: obs})\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneglogp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ACER_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ACER.load(\"ACER_model\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
